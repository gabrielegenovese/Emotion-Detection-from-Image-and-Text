{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVlvNevZo1Oh",
        "outputId": "f7a3095f-0177-4155-82d5-f6c3ae3bf4b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/AIExam/data.zip /content\n",
        "!mkdir dataset\n",
        "!unzip data.zip"
      ],
      "metadata": {
        "id": "acBq0WM-QyzP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import LSTM, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import csv\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Function to load data from CSV and images\n",
        "def load_data(file_path):\n",
        "    data = []\n",
        "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
        "        csv_reader = csv.reader(csvfile)\n",
        "        next(csv_reader, None)\n",
        "        for row in csv_reader:\n",
        "            text, image_path, emotion = row\n",
        "            img = Image.open(image_path).convert('RGB')\n",
        "            img = img.resize((64, 64))\n",
        "            img_array = np.array(img) / 255.0\n",
        "            entry = {'text': text, 'image_data': img_array, 'emotion': emotion}\n",
        "            data.append(entry)\n",
        "    return data\n",
        "\n",
        "# Load data\n",
        "file_path = \"data/processed/text_image_emotion.csv\"\n",
        "data = load_data(file_path)"
      ],
      "metadata": {
        "id": "1YJojNd8uctg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to numpy arrays\n",
        "texts = [entry['text'] for entry in data]\n",
        "images = np.array([entry['image_data'] for entry in data])\n",
        "emotions = [entry['emotion'] for entry in data]\n",
        "\n",
        "# Encode emotions\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_emotions = label_encoder.fit_transform(emotions)\n",
        "one_hot_emotions = tf.keras.utils.to_categorical(encoded_emotions, num_classes=len(label_encoder.classes_))\n",
        "\n",
        "# Tokenize the text\n",
        "max_words = 10000\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(texts)\n",
        "text_sequences = tokenizer.texts_to_sequences(texts)\n",
        "text_padded = pad_sequences(text_sequences, padding='post')\n",
        "\n",
        "# Split data into training and testing sets\n",
        "text_train, text_test, image_train, image_test, emotion_train, emotion_test = train_test_split(\n",
        "    text_padded, images, one_hot_emotions, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "nWZ8cAV8uqRC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the neural network model\n",
        "text_input = layers.Input(shape=(text_padded.shape[1],), dtype=tf.int32)\n",
        "embedding_layer = layers.Embedding(input_dim=max_words, output_dim=16, input_length=text_padded.shape[1])(text_input)\n",
        "lstm_layer = LSTM(16)(embedding_layer)\n",
        "text_flatten = layers.Flatten()(lstm_layer)\n",
        "\n",
        "image_input = layers.Input(shape=(64, 64, 3))\n",
        "conv_layer = layers.Conv2D(32, (3, 3), activation='relu')(image_input)\n",
        "pooling_layer = layers.MaxPooling2D((2, 2))(conv_layer)\n",
        "flatten_layer = layers.Flatten()(pooling_layer)\n",
        "\n",
        "# Concatenate the flattened text and image layers\n",
        "concatenated = layers.Concatenate()([text_flatten, flatten_layer])\n",
        "# Add Dropout for regularization\n",
        "dropout_layer = layers.Dropout(0.5)(concatenated)\n",
        "dense_layer = layers.Dense(64, activation='relu')(dropout_layer)\n",
        "output_layer = layers.Dense(len(label_encoder.classes_), activation='softmax')(dense_layer)\n",
        "\n",
        "model = models.Model(inputs=[text_input, image_input], outputs=output_layer)\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Add ModelCheckpoint callback to save the best model\n",
        "checkpoint_callback = ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor=\"val_accuracy\", mode=\"max\")\n",
        "\n",
        "# Create an ImageDataGenerator for data augmentation\n",
        "image_data_generator = ImageDataGenerator(rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "\n",
        "# Aggiungi callback per l'early stopping\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT1dMa5Uuxzu",
        "outputId": "5080b2d5-a423-4c0b-d7ae-39b190524c29"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 34)]                 0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 64, 64, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, 34, 16)               160000    ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 62, 62, 32)           896       ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 (None, 16)                   2112      ['embedding[0][0]']           \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 31, 31, 32)           0         ['conv2d[0][0]']              \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 16)                   0         ['lstm[0][0]']                \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)         (None, 30752)                0         ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 30768)                0         ['flatten[0][0]',             \n",
            "                                                                     'flatten_1[0][0]']           \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 30768)                0         ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 64)                   1969216   ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 7)                    455       ['dense[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2132679 (8.14 MB)\n",
            "Trainable params: 2132679 (8.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KAhvriwdqhHS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b80e51bb-285b-4542-bfe6-79c4bc973ca2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "585/585 [==============================] - 28s 37ms/step - loss: 1.6526 - accuracy: 0.3435 - val_loss: 1.5725 - val_accuracy: 0.4030\n",
            "Epoch 2/30\n",
            "  9/585 [..............................] - ETA: 3s - loss: 1.5783 - accuracy: 0.4028"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "585/585 [==============================] - 6s 11ms/step - loss: 1.5129 - accuracy: 0.4290 - val_loss: 1.4618 - val_accuracy: 0.4600\n",
            "Epoch 3/30\n",
            "585/585 [==============================] - 7s 11ms/step - loss: 1.4362 - accuracy: 0.4655 - val_loss: 1.4302 - val_accuracy: 0.4662\n",
            "Epoch 4/30\n",
            "585/585 [==============================] - 8s 13ms/step - loss: 1.3786 - accuracy: 0.4879 - val_loss: 1.3383 - val_accuracy: 0.5152\n",
            "Epoch 5/30\n",
            "585/585 [==============================] - 7s 11ms/step - loss: 1.2416 - accuracy: 0.5446 - val_loss: 1.2641 - val_accuracy: 0.5363\n",
            "Epoch 6/30\n",
            "585/585 [==============================] - 5s 8ms/step - loss: 1.1609 - accuracy: 0.5813 - val_loss: 1.2334 - val_accuracy: 0.5498\n",
            "Epoch 7/30\n",
            "585/585 [==============================] - 4s 7ms/step - loss: 1.1039 - accuracy: 0.5985 - val_loss: 1.2356 - val_accuracy: 0.5479\n",
            "Epoch 8/30\n",
            "585/585 [==============================] - 5s 9ms/step - loss: 1.0643 - accuracy: 0.6135 - val_loss: 1.2163 - val_accuracy: 0.5564\n",
            "Epoch 9/30\n",
            "585/585 [==============================] - 4s 8ms/step - loss: 1.0238 - accuracy: 0.6355 - val_loss: 1.2105 - val_accuracy: 0.5609\n",
            "Epoch 10/30\n",
            "585/585 [==============================] - 5s 8ms/step - loss: 0.9834 - accuracy: 0.6499 - val_loss: 1.2172 - val_accuracy: 0.5553\n",
            "Epoch 11/30\n",
            "585/585 [==============================] - 5s 8ms/step - loss: 0.9521 - accuracy: 0.6611 - val_loss: 1.2273 - val_accuracy: 0.5590\n",
            "Epoch 12/30\n",
            "585/585 [==============================] - 5s 8ms/step - loss: 0.9175 - accuracy: 0.6739 - val_loss: 1.2267 - val_accuracy: 0.5632\n",
            "Epoch 13/30\n",
            "585/585 [==============================] - 5s 9ms/step - loss: 0.8851 - accuracy: 0.6881 - val_loss: 1.2334 - val_accuracy: 0.5650\n",
            "Epoch 14/30\n",
            "585/585 [==============================] - 4s 7ms/step - loss: 0.8554 - accuracy: 0.6998 - val_loss: 1.2437 - val_accuracy: 0.5639\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7dac91311870>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "\n",
        "model.fit([text_train, image_train], emotion_train, epochs=30, validation_data=([text_test, image_test], emotion_test), callbacks=[checkpoint_callback, early_stopping_callback])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "evaluation_results = model.evaluate([text_test, image_test], emotion_test)\n",
        "# Print the evaluation results\n",
        "print(f\"Loss: {evaluation_results[0]}, Accuracy: {evaluation_results[1]}\")\n",
        "# Make predictions on new test data\n",
        "predictions = model.predict([text_test, image_test])\n",
        "# Print the predicted probabilities for each class\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "axTQtzfZvWAX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92a06395-291f-4207-a5b6-db42617b29a0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "147/147 [==============================] - 1s 4ms/step - loss: 1.2105 - accuracy: 0.5609\n",
            "Loss: 1.2104779481887817, Accuracy: 0.5608974099159241\n",
            "147/147 [==============================] - 0s 3ms/step\n",
            "[[8.81730055e-04 3.92039627e-04 3.64822889e-04 ... 4.17445414e-03\n",
            "  7.53876986e-04 4.63532197e-04]\n",
            " [5.24454452e-02 2.31959708e-02 1.16633996e-02 ... 6.51205361e-01\n",
            "  7.07607344e-02 5.63853085e-02]\n",
            " [1.79932699e-01 3.86128947e-02 1.06525704e-01 ... 2.71224659e-02\n",
            "  3.36882547e-02 6.05008602e-01]\n",
            " ...\n",
            " [3.84986222e-01 1.61189493e-02 2.21460387e-02 ... 2.73633450e-01\n",
            "  9.33439583e-02 2.04174861e-01]\n",
            " [2.82380670e-01 2.31594630e-02 2.37093680e-02 ... 3.01467091e-01\n",
            "  3.02852720e-01 3.76921222e-02]\n",
            " [4.75906860e-03 7.25496793e-04 1.22725056e-03 ... 2.47282639e-01\n",
            "  6.50194474e-03 5.77207562e-03]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "XO1g-sXM67RE",
        "ZMJMJv39q2_A",
        "wGaIsKTZwAyk",
        "pLVj68WNbroz",
        "_A_fUtfewLbt",
        "027rYoBZAOjM",
        "OH5MFA5QQHre",
        "72I3_3flS4VN",
        "tCmBnkKhPNZq",
        "DfUuXg-xQHKv",
        "aNLqQ5k_Sfih",
        "SibMuTSPUouw"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}