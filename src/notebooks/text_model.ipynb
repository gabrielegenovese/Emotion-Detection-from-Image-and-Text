{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Modello di predizione delle emozioni dato del testo"
      ],
      "metadata": {
        "id": "FCweZc7x21_x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data retrival"
      ],
      "metadata": {
        "id": "NirGlgMbHea4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVlvNevZo1Oh",
        "outputId": "bb7fb1f2-08d2-4fd9-b144-6950cad92875"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/AIExam/train_ekmann.csv /content\n",
        "!pip install contractions emoji ekphrasis --quiet"
      ],
      "metadata": {
        "id": "acBq0WM-QyzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import LSTM, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import csv\n",
        "from PIL import Image\n",
        "import re\n",
        "import numpy as np\n",
        "import contractions, emoji\n",
        "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
        "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
        "from ekphrasis.dicts.emoticons import emoticons\n",
        "\n",
        "EPOCH = 100"
      ],
      "metadata": {
        "id": "czejXtxc7u-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(file_path):\n",
        "    data = []\n",
        "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
        "        csv_reader = csv.reader(csvfile)\n",
        "        next(csv_reader, None)\n",
        "        for row in csv_reader:\n",
        "            text, emotion, id = row\n",
        "            entry = {'text': text, 'emotion': emotion, 'id': id}\n",
        "            data.append(entry)\n",
        "    return data\n",
        "\n",
        "file_path = \"train_ekmann.csv\"\n",
        "data = load_data(file_path)\n",
        "print(data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uI1I4NJH5lDb",
        "outputId": "c67ba223-7c04-4a80-f565-043579093282"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': \"My favourite food is anything I didn't have to cook myself.\", 'emotion': 'neutral', 'id': 'eebbqej'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [entry['text'] for entry in data]\n",
        "emotions = [entry['emotion'] for entry in data]\n",
        "\n",
        "def show_data(i):\n",
        "  print(\"Testo associato:\", texts[i])\n",
        "  print(\"Emozione:\", emotions[i])\n",
        "\n",
        "show_data(123)\n",
        "\n",
        "i = 12345\n",
        "show_data(i)"
      ],
      "metadata": {
        "id": "3r1gj9Qb8lYn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acb90b07-fc47-4d3b-8a5d-140c8838ffc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testo associato: Three words, no subtlety. \"Dude. Stop. Seriously.\" \n",
            "Emozione: anger\n",
            "Testo associato: Weird, just got back from the one on Grand 45 min ago and I got in and out no problem. \n",
            "Emozione: neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding delle emozioni"
      ],
      "metadata": {
        "id": "3PKEtV7i9Z-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "encoded_emotions = label_encoder.fit_transform(emotions)\n",
        "categorical_emotions = tf.keras.utils.to_categorical(encoded_emotions, num_classes=len(label_encoder.classes_))\n",
        "\n",
        "custom_p = lambda n: print(\"emotion\\t \", n, \"  \\tis encoded with the number\\t\", encoded_emotions[emotions.index(n)], \"\\tand vector\\t\", categorical_emotions[emotions.index(n)])\n",
        "\n",
        "custom_p(\"anger\")\n",
        "custom_p(\"disgust\")\n",
        "custom_p(\"fear\")\n",
        "custom_p(\"joy\")\n",
        "custom_p(\"neutral\")\n",
        "custom_p(\"sadness\")\n",
        "custom_p(\"surprise\")"
      ],
      "metadata": {
        "id": "s-1lH06f91uX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4df07acc-2ed8-4ed9-ad14-9e758523b2d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emotion\t  anger   \tis encoded with the number\t 0 \tand vector\t [1. 0. 0. 0. 0. 0. 0.]\n",
            "emotion\t  disgust   \tis encoded with the number\t 1 \tand vector\t [0. 1. 0. 0. 0. 0. 0.]\n",
            "emotion\t  fear   \tis encoded with the number\t 2 \tand vector\t [0. 0. 1. 0. 0. 0. 0.]\n",
            "emotion\t  joy   \tis encoded with the number\t 3 \tand vector\t [0. 0. 0. 1. 0. 0. 0.]\n",
            "emotion\t  neutral   \tis encoded with the number\t 4 \tand vector\t [0. 0. 0. 0. 1. 0. 0.]\n",
            "emotion\t  sadness   \tis encoded with the number\t 5 \tand vector\t [0. 0. 0. 0. 0. 1. 0.]\n",
            "emotion\t  surprise   \tis encoded with the number\t 6 \tand vector\t [0. 0. 0. 0. 0. 0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-processing del testo"
      ],
      "metadata": {
        "id": "QgreP5pM9AEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 20000\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(texts)\n",
        "text_sequences = tokenizer.texts_to_sequences(texts)\n",
        "text_padded = pad_sequences(text_sequences, padding='post')"
      ],
      "metadata": {
        "id": "nWZ8cAV8uqRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creazione del dataset\n",
        "Dividiamo il dataset nella seguente maniera:\n",
        "*   train data: 80%  \n",
        "*   validation data: 10%  \n",
        "*   test data: 10%  "
      ],
      "metadata": {
        "id": "vf0JWYH2-jVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_train, text_test_temp, emotion_train, emotion_test_temp = train_test_split(\n",
        "    text_padded, categorical_emotions, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "text_test, text_val, emotion_test, emotion_val = train_test_split(\n",
        "    text_test_temp, emotion_test_temp, test_size=0.5, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Lunghezza dati di train:\", len(text_train))\n",
        "print(\"Lunghezza dati di validation:\", len(text_val))\n",
        "print(\"Lunghezza dati di test:\", len(text_test))"
      ],
      "metadata": {
        "id": "x94Fv1noeEvR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce0af95e-cedc-4f5a-f927-77810a705a3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lunghezza dati di train: 34728\n",
            "Lunghezza dati di validation: 4341\n",
            "Lunghezza dati di test: 4341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prima prova"
      ],
      "metadata": {
        "id": "mZdTj9B9_iAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_input = layers.Input(shape=text_padded.shape[1], dtype=tf.int32)\n",
        "text_dense_layer = layers.Dense(64, activation='relu')(text_input)\n",
        "\n",
        "dropout_layer = layers.Dropout(0.5)(text_dense_layer)\n",
        "output_layer = layers.Dense(len(label_encoder.classes_), activation='softmax')(dropout_layer)\n",
        "\n",
        "model = models.Model(inputs=text_input, outputs=output_layer)\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy', metrics.Precision(), metrics.Recall()])\n",
        "model.summary()\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor=\"val_accuracy\", mode=\"max\")\n",
        "\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "TEJPlvWd_yM4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0890cbbf-3965-48e5-93d6-fd39cdc6c72a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 142)]             0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 64)                9152      \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 7)                 455       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9607 (37.53 KB)\n",
            "Trainable params: 9607 (37.53 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(text_train, emotion_train, epochs=EPOCH, validation_data=(text_val, emotion_val), callbacks=[checkpoint_callback, early_stopping_callback])\n",
        "\n",
        "evaluation_results = model.evaluate(text_test, emotion_test)\n",
        "print(f\"Loss: {round(evaluation_results[0], 2)}, Accuracy: {round(evaluation_results[1], 2)}\")"
      ],
      "metadata": {
        "id": "roZ91CiVCdi4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a26096e-d618-4d29-82e9-cd38e0141f26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1086/1086 [==============================] - 6s 4ms/step - loss: 212.3520 - accuracy: 0.2671 - precision_4: 0.2510 - recall_4: 0.2107 - val_loss: 8.2950 - val_accuracy: 0.3402 - val_precision_4: 0.2891 - val_recall_4: 0.1136\n",
            "Epoch 2/100\n",
            "  46/1086 [>.............................] - ETA: 3s - loss: 8.6000 - accuracy: 0.3431 - precision_4: 0.2860 - recall_4: 0.0931"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1086/1086 [==============================] - 6s 6ms/step - loss: 4.6643 - accuracy: 0.3561 - precision_4: 0.2752 - recall_4: 0.0470 - val_loss: 2.2667 - val_accuracy: 0.3628 - val_precision_4: 0.3137 - val_recall_4: 0.0196\n",
            "Epoch 3/100\n",
            "1086/1086 [==============================] - 8s 8ms/step - loss: 2.0636 - accuracy: 0.3658 - precision_4: 0.2944 - recall_4: 0.0212 - val_loss: 1.7245 - val_accuracy: 0.3674 - val_precision_4: 0.3318 - val_recall_4: 0.0327\n",
            "Epoch 4/100\n",
            "1086/1086 [==============================] - 6s 5ms/step - loss: 1.7160 - accuracy: 0.3696 - precision_4: 0.2725 - recall_4: 0.0092 - val_loss: 1.6672 - val_accuracy: 0.3697 - val_precision_4: 0.3051 - val_recall_4: 0.0124\n",
            "Epoch 5/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.6161 - accuracy: 0.3703 - precision_4: 0.2896 - recall_4: 0.0037 - val_loss: 1.5692 - val_accuracy: 0.3709 - val_precision_4: 0.4074 - val_recall_4: 0.0025\n",
            "Epoch 6/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.5912 - accuracy: 0.3717 - precision_4: 0.2952 - recall_4: 0.0014 - val_loss: 1.5506 - val_accuracy: 0.3700 - val_precision_4: 0.3750 - val_recall_4: 0.0021\n",
            "Epoch 7/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.5659 - accuracy: 0.3722 - precision_4: 0.3718 - recall_4: 8.3506e-04 - val_loss: 1.5683 - val_accuracy: 0.3702 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
            "Epoch 8/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.5394 - accuracy: 0.3727 - precision_4: 0.5000 - recall_4: 8.9265e-04 - val_loss: 1.5520 - val_accuracy: 0.3702 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
            "Epoch 9/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.5441 - accuracy: 0.3724 - precision_4: 0.4359 - recall_4: 4.8952e-04 - val_loss: 1.5478 - val_accuracy: 0.3707 - val_precision_4: 0.2500 - val_recall_4: 2.3036e-04\n",
            "Epoch 10/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.5336 - accuracy: 0.3726 - precision_4: 0.6000 - recall_4: 5.1831e-04 - val_loss: 1.5471 - val_accuracy: 0.3707 - val_precision_4: 0.3333 - val_recall_4: 2.3036e-04\n",
            "Epoch 11/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.5404 - accuracy: 0.3724 - precision_4: 0.4800 - recall_4: 3.4554e-04 - val_loss: 1.5404 - val_accuracy: 0.3707 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
            "Epoch 12/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.5347 - accuracy: 0.3725 - precision_4: 0.5333 - recall_4: 2.3036e-04 - val_loss: 1.5422 - val_accuracy: 0.3704 - val_precision_4: 0.2500 - val_recall_4: 2.3036e-04\n",
            "Epoch 13/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.5337 - accuracy: 0.3725 - precision_4: 0.7333 - recall_4: 3.1675e-04 - val_loss: 1.5419 - val_accuracy: 0.3707 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
            "Epoch 14/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.5392 - accuracy: 0.3725 - precision_4: 0.6471 - recall_4: 3.1675e-04 - val_loss: 1.5403 - val_accuracy: 0.3707 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
            "Epoch 15/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.5327 - accuracy: 0.3724 - precision_4: 0.7500 - recall_4: 1.7277e-04 - val_loss: 1.5403 - val_accuracy: 0.3707 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
            "Epoch 16/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.5335 - accuracy: 0.3725 - precision_4: 0.7273 - recall_4: 2.3036e-04 - val_loss: 1.5403 - val_accuracy: 0.3707 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
            "Epoch 17/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.5343 - accuracy: 0.3725 - precision_4: 0.8571 - recall_4: 1.7277e-04 - val_loss: 1.5403 - val_accuracy: 0.3707 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
            "Epoch 18/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.5326 - accuracy: 0.3725 - precision_4: 1.0000 - recall_4: 1.4398e-04 - val_loss: 1.5404 - val_accuracy: 0.3707 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
            "Epoch 19/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.5418 - accuracy: 0.3725 - precision_4: 0.4737 - recall_4: 5.1831e-04 - val_loss: 1.5404 - val_accuracy: 0.3707 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
            "Epoch 20/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.5385 - accuracy: 0.3724 - precision_4: 0.5588 - recall_4: 5.4711e-04 - val_loss: 1.5420 - val_accuracy: 0.3707 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
            "136/136 [==============================] - 0s 3ms/step - loss: 1.5235 - accuracy: 0.3859 - precision_4: 0.3333 - recall_4: 2.3036e-04\n",
            "Loss: 1.52, Accuracy: 0.39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss: 1.52, Accuracy: 0.39, Precision: 0.33, Recall: 0.0002."
      ],
      "metadata": {
        "id": "9pgCa3mCDWR4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seconda prova"
      ],
      "metadata": {
        "id": "cGUb6lQXKjao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_input = layers.Input(shape=text_padded.shape[1], dtype=tf.int32)\n",
        "embedding_layer = layers.Embedding(input_dim=max_words, output_dim=8, input_length=text_padded.shape[1])(text_input)\n",
        "text_flatten = layers.Flatten()(embedding_layer)\n",
        "\n",
        "dropout_layer = layers.Dropout(0.5)(text_flatten)\n",
        "output_layer = layers.Dense(len(label_encoder.classes_), activation='softmax')(dropout_layer)\n",
        "\n",
        "model = models.Model(inputs=text_input, outputs=output_layer)\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy', metrics.Precision(), metrics.Recall()])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "KmIRHMY_KnN2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0177681-c7a3-40b3-b2a3-c544e5403f46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_9 (InputLayer)        [(None, 142)]             0         \n",
            "                                                                 \n",
            " embedding_5 (Embedding)     (None, 142, 8)            160000    \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 1136)              0         \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 1136)              0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 7)                 7959      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 167959 (656.09 KB)\n",
            "Trainable params: 167959 (656.09 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(text_train, emotion_train, epochs=EPOCH, validation_data=(text_val, emotion_val), callbacks=[checkpoint_callback, early_stopping_callback])\n",
        "\n",
        "evaluation_results = model.evaluate(text_test, emotion_test)\n",
        "print(f\"Loss: {round(evaluation_results[0], 2)}, Accuracy: {round(evaluation_results[1], 2)}\")"
      ],
      "metadata": {
        "id": "5qN0ClA2M9ws",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3ab6e2c-be41-4304-b085-70dcc814a951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1086/1086 [==============================] - 20s 17ms/step - loss: 1.5820 - accuracy: 0.3630 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 1.5343 - val_accuracy: 0.3709 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
            "Epoch 2/100\n",
            "1086/1086 [==============================] - 7s 6ms/step - loss: 1.5297 - accuracy: 0.3722 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 1.5294 - val_accuracy: 0.3709 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
            "Epoch 3/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.5214 - accuracy: 0.3774 - precision_5: 0.9333 - recall_5: 4.0313e-04 - val_loss: 1.5186 - val_accuracy: 0.3709 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
            "Epoch 4/100\n",
            "1086/1086 [==============================] - 6s 5ms/step - loss: 1.5057 - accuracy: 0.3961 - precision_5: 0.9295 - recall_5: 0.0084 - val_loss: 1.5005 - val_accuracy: 0.3928 - val_precision_5: 0.9859 - val_recall_5: 0.0161\n",
            "Epoch 5/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.4838 - accuracy: 0.4282 - precision_5: 0.9087 - recall_5: 0.0370 - val_loss: 1.4787 - val_accuracy: 0.4540 - val_precision_5: 0.9643 - val_recall_5: 0.0373\n",
            "Epoch 6/100\n",
            "1086/1086 [==============================] - 8s 7ms/step - loss: 1.4580 - accuracy: 0.4624 - precision_5: 0.8859 - recall_5: 0.0677 - val_loss: 1.4542 - val_accuracy: 0.4679 - val_precision_5: 0.9387 - val_recall_5: 0.0811\n",
            "Epoch 7/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 1.4323 - accuracy: 0.4822 - precision_5: 0.8644 - recall_5: 0.0982 - val_loss: 1.4306 - val_accuracy: 0.4792 - val_precision_5: 0.9192 - val_recall_5: 0.1126\n",
            "Epoch 8/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.4079 - accuracy: 0.4958 - precision_5: 0.8491 - recall_5: 0.1222 - val_loss: 1.4081 - val_accuracy: 0.4921 - val_precision_5: 0.9000 - val_recall_5: 0.1306\n",
            "Epoch 9/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.3846 - accuracy: 0.5060 - precision_5: 0.8368 - recall_5: 0.1454 - val_loss: 1.3880 - val_accuracy: 0.4957 - val_precision_5: 0.8763 - val_recall_5: 0.1534\n",
            "Epoch 10/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.3632 - accuracy: 0.5130 - precision_5: 0.8219 - recall_5: 0.1680 - val_loss: 1.3690 - val_accuracy: 0.5045 - val_precision_5: 0.8664 - val_recall_5: 0.1659\n",
            "Epoch 11/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 1.3420 - accuracy: 0.5202 - precision_5: 0.8172 - recall_5: 0.1918 - val_loss: 1.3518 - val_accuracy: 0.5132 - val_precision_5: 0.8621 - val_recall_5: 0.1728\n",
            "Epoch 12/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.3248 - accuracy: 0.5304 - precision_5: 0.8073 - recall_5: 0.2094 - val_loss: 1.3366 - val_accuracy: 0.5172 - val_precision_5: 0.8461 - val_recall_5: 0.1937\n",
            "Epoch 13/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 1.3083 - accuracy: 0.5336 - precision_5: 0.8042 - recall_5: 0.2310 - val_loss: 1.3232 - val_accuracy: 0.5218 - val_precision_5: 0.8285 - val_recall_5: 0.2158\n",
            "Epoch 14/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.2931 - accuracy: 0.5411 - precision_5: 0.7999 - recall_5: 0.2484 - val_loss: 1.3115 - val_accuracy: 0.5308 - val_precision_5: 0.8245 - val_recall_5: 0.2142\n",
            "Epoch 15/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 1.2766 - accuracy: 0.5479 - precision_5: 0.8006 - recall_5: 0.2632 - val_loss: 1.2991 - val_accuracy: 0.5305 - val_precision_5: 0.8102 - val_recall_5: 0.2458\n",
            "Epoch 16/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 1.2639 - accuracy: 0.5515 - precision_5: 0.7913 - recall_5: 0.2799 - val_loss: 1.2890 - val_accuracy: 0.5372 - val_precision_5: 0.7999 - val_recall_5: 0.2550\n",
            "Epoch 17/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.2508 - accuracy: 0.5536 - precision_5: 0.7939 - recall_5: 0.2928 - val_loss: 1.2797 - val_accuracy: 0.5402 - val_precision_5: 0.7888 - val_recall_5: 0.2658\n",
            "Epoch 18/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 1.2408 - accuracy: 0.5613 - precision_5: 0.7961 - recall_5: 0.3035 - val_loss: 1.2714 - val_accuracy: 0.5413 - val_precision_5: 0.7807 - val_recall_5: 0.2797\n",
            "Epoch 19/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 1.2307 - accuracy: 0.5646 - precision_5: 0.7919 - recall_5: 0.3148 - val_loss: 1.2643 - val_accuracy: 0.5437 - val_precision_5: 0.7716 - val_recall_5: 0.2942\n",
            "Epoch 20/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.2169 - accuracy: 0.5686 - precision_5: 0.7922 - recall_5: 0.3297 - val_loss: 1.2566 - val_accuracy: 0.5483 - val_precision_5: 0.7698 - val_recall_5: 0.2997\n",
            "Epoch 21/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 1.2101 - accuracy: 0.5735 - precision_5: 0.7862 - recall_5: 0.3341 - val_loss: 1.2501 - val_accuracy: 0.5517 - val_precision_5: 0.7751 - val_recall_5: 0.2985\n",
            "Epoch 22/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.1987 - accuracy: 0.5774 - precision_5: 0.7886 - recall_5: 0.3437 - val_loss: 1.2435 - val_accuracy: 0.5531 - val_precision_5: 0.7710 - val_recall_5: 0.3110\n",
            "Epoch 23/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.1905 - accuracy: 0.5801 - precision_5: 0.7899 - recall_5: 0.3527 - val_loss: 1.2375 - val_accuracy: 0.5552 - val_precision_5: 0.7718 - val_recall_5: 0.3117\n",
            "Epoch 24/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.1806 - accuracy: 0.5872 - precision_5: 0.7902 - recall_5: 0.3585 - val_loss: 1.2322 - val_accuracy: 0.5568 - val_precision_5: 0.7666 - val_recall_5: 0.3186\n",
            "Epoch 25/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.1728 - accuracy: 0.5857 - precision_5: 0.7889 - recall_5: 0.3677 - val_loss: 1.2270 - val_accuracy: 0.5607 - val_precision_5: 0.7671 - val_recall_5: 0.3172\n",
            "Epoch 26/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.1627 - accuracy: 0.5917 - precision_5: 0.7922 - recall_5: 0.3751 - val_loss: 1.2229 - val_accuracy: 0.5593 - val_precision_5: 0.7542 - val_recall_5: 0.3379\n",
            "Epoch 27/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.1543 - accuracy: 0.5941 - precision_5: 0.7901 - recall_5: 0.3819 - val_loss: 1.2174 - val_accuracy: 0.5662 - val_precision_5: 0.7618 - val_recall_5: 0.3285\n",
            "Epoch 28/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.1446 - accuracy: 0.5970 - precision_5: 0.7917 - recall_5: 0.3886 - val_loss: 1.2128 - val_accuracy: 0.5692 - val_precision_5: 0.7590 - val_recall_5: 0.3294\n",
            "Epoch 29/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.1419 - accuracy: 0.5977 - precision_5: 0.7892 - recall_5: 0.3924 - val_loss: 1.2093 - val_accuracy: 0.5690 - val_precision_5: 0.7542 - val_recall_5: 0.3449\n",
            "Epoch 30/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.1298 - accuracy: 0.6041 - precision_5: 0.7963 - recall_5: 0.4039 - val_loss: 1.2048 - val_accuracy: 0.5713 - val_precision_5: 0.7608 - val_recall_5: 0.3400\n",
            "Epoch 31/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 1.1228 - accuracy: 0.6047 - precision_5: 0.7932 - recall_5: 0.4075 - val_loss: 1.2009 - val_accuracy: 0.5734 - val_precision_5: 0.7556 - val_recall_5: 0.3398\n",
            "Epoch 32/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.1144 - accuracy: 0.6092 - precision_5: 0.7917 - recall_5: 0.4097 - val_loss: 1.1972 - val_accuracy: 0.5741 - val_precision_5: 0.7555 - val_recall_5: 0.3495\n",
            "Epoch 33/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.1078 - accuracy: 0.6117 - precision_5: 0.7942 - recall_5: 0.4147 - val_loss: 1.1932 - val_accuracy: 0.5734 - val_precision_5: 0.7488 - val_recall_5: 0.3591\n",
            "Epoch 34/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.1026 - accuracy: 0.6145 - precision_5: 0.7962 - recall_5: 0.4209 - val_loss: 1.1902 - val_accuracy: 0.5771 - val_precision_5: 0.7529 - val_recall_5: 0.3531\n",
            "Epoch 35/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 1.0971 - accuracy: 0.6149 - precision_5: 0.7953 - recall_5: 0.4250 - val_loss: 1.1872 - val_accuracy: 0.5759 - val_precision_5: 0.7518 - val_recall_5: 0.3559\n",
            "Epoch 36/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.0909 - accuracy: 0.6171 - precision_5: 0.7983 - recall_5: 0.4318 - val_loss: 1.1845 - val_accuracy: 0.5773 - val_precision_5: 0.7457 - val_recall_5: 0.3660\n",
            "Epoch 37/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.0799 - accuracy: 0.6224 - precision_5: 0.7953 - recall_5: 0.4335 - val_loss: 1.1816 - val_accuracy: 0.5784 - val_precision_5: 0.7433 - val_recall_5: 0.3681\n",
            "Epoch 38/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 1.0741 - accuracy: 0.6233 - precision_5: 0.7993 - recall_5: 0.4373 - val_loss: 1.1793 - val_accuracy: 0.5791 - val_precision_5: 0.7404 - val_recall_5: 0.3686\n",
            "Epoch 39/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.0692 - accuracy: 0.6292 - precision_5: 0.7977 - recall_5: 0.4425 - val_loss: 1.1772 - val_accuracy: 0.5801 - val_precision_5: 0.7419 - val_recall_5: 0.3727\n",
            "Epoch 40/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.0615 - accuracy: 0.6282 - precision_5: 0.8040 - recall_5: 0.4497 - val_loss: 1.1742 - val_accuracy: 0.5828 - val_precision_5: 0.7430 - val_recall_5: 0.3690\n",
            "Epoch 41/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.0565 - accuracy: 0.6310 - precision_5: 0.8029 - recall_5: 0.4491 - val_loss: 1.1718 - val_accuracy: 0.5819 - val_precision_5: 0.7437 - val_recall_5: 0.3730\n",
            "Epoch 42/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.0492 - accuracy: 0.6331 - precision_5: 0.8017 - recall_5: 0.4538 - val_loss: 1.1697 - val_accuracy: 0.5819 - val_precision_5: 0.7403 - val_recall_5: 0.3808\n",
            "Epoch 43/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.0408 - accuracy: 0.6369 - precision_5: 0.8020 - recall_5: 0.4595 - val_loss: 1.1678 - val_accuracy: 0.5851 - val_precision_5: 0.7421 - val_recall_5: 0.3771\n",
            "Epoch 44/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.0378 - accuracy: 0.6386 - precision_5: 0.8041 - recall_5: 0.4603 - val_loss: 1.1670 - val_accuracy: 0.5844 - val_precision_5: 0.7412 - val_recall_5: 0.3755\n",
            "Epoch 45/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.0323 - accuracy: 0.6430 - precision_5: 0.8026 - recall_5: 0.4658 - val_loss: 1.1642 - val_accuracy: 0.5849 - val_precision_5: 0.7358 - val_recall_5: 0.3868\n",
            "Epoch 46/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.0267 - accuracy: 0.6437 - precision_5: 0.8040 - recall_5: 0.4681 - val_loss: 1.1631 - val_accuracy: 0.5844 - val_precision_5: 0.7340 - val_recall_5: 0.3884\n",
            "Epoch 47/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.0208 - accuracy: 0.6475 - precision_5: 0.8068 - recall_5: 0.4710 - val_loss: 1.1611 - val_accuracy: 0.5877 - val_precision_5: 0.7381 - val_recall_5: 0.3842\n",
            "Epoch 48/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.0130 - accuracy: 0.6489 - precision_5: 0.8058 - recall_5: 0.4760 - val_loss: 1.1593 - val_accuracy: 0.5879 - val_precision_5: 0.7397 - val_recall_5: 0.3863\n",
            "Epoch 49/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 1.0087 - accuracy: 0.6495 - precision_5: 0.8058 - recall_5: 0.4788 - val_loss: 1.1579 - val_accuracy: 0.5886 - val_precision_5: 0.7340 - val_recall_5: 0.3909\n",
            "Epoch 50/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.0019 - accuracy: 0.6528 - precision_5: 0.8089 - recall_5: 0.4854 - val_loss: 1.1565 - val_accuracy: 0.5886 - val_precision_5: 0.7302 - val_recall_5: 0.3928\n",
            "Epoch 51/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.0004 - accuracy: 0.6554 - precision_5: 0.8056 - recall_5: 0.4881 - val_loss: 1.1562 - val_accuracy: 0.5858 - val_precision_5: 0.7306 - val_recall_5: 0.3916\n",
            "Epoch 52/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 0.9930 - accuracy: 0.6575 - precision_5: 0.8094 - recall_5: 0.4913 - val_loss: 1.1553 - val_accuracy: 0.5867 - val_precision_5: 0.7282 - val_recall_5: 0.3955\n",
            "Epoch 53/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 0.9866 - accuracy: 0.6580 - precision_5: 0.8090 - recall_5: 0.4939 - val_loss: 1.1546 - val_accuracy: 0.5856 - val_precision_5: 0.7253 - val_recall_5: 0.3990\n",
            "Epoch 54/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 0.9843 - accuracy: 0.6594 - precision_5: 0.8075 - recall_5: 0.4960 - val_loss: 1.1542 - val_accuracy: 0.5860 - val_precision_5: 0.7213 - val_recall_5: 0.4024\n",
            "Epoch 55/100\n",
            "1086/1086 [==============================] - 6s 5ms/step - loss: 0.9813 - accuracy: 0.6615 - precision_5: 0.8079 - recall_5: 0.4967 - val_loss: 1.1529 - val_accuracy: 0.5835 - val_precision_5: 0.7187 - val_recall_5: 0.4103\n",
            "Epoch 56/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 0.9729 - accuracy: 0.6631 - precision_5: 0.8104 - recall_5: 0.5004 - val_loss: 1.1517 - val_accuracy: 0.5853 - val_precision_5: 0.7221 - val_recall_5: 0.4094\n",
            "Epoch 57/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 0.9718 - accuracy: 0.6653 - precision_5: 0.8086 - recall_5: 0.5023 - val_loss: 1.1511 - val_accuracy: 0.5853 - val_precision_5: 0.7230 - val_recall_5: 0.4082\n",
            "Epoch 58/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 0.9645 - accuracy: 0.6670 - precision_5: 0.8117 - recall_5: 0.5074 - val_loss: 1.1504 - val_accuracy: 0.5858 - val_precision_5: 0.7197 - val_recall_5: 0.4128\n",
            "Epoch 59/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 0.9586 - accuracy: 0.6695 - precision_5: 0.8148 - recall_5: 0.5109 - val_loss: 1.1510 - val_accuracy: 0.5837 - val_precision_5: 0.7145 - val_recall_5: 0.4151\n",
            "Epoch 60/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 0.9569 - accuracy: 0.6674 - precision_5: 0.8108 - recall_5: 0.5108 - val_loss: 1.1498 - val_accuracy: 0.5847 - val_precision_5: 0.7229 - val_recall_5: 0.4068\n",
            "Epoch 61/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 0.9504 - accuracy: 0.6726 - precision_5: 0.8125 - recall_5: 0.5174 - val_loss: 1.1487 - val_accuracy: 0.5847 - val_precision_5: 0.7191 - val_recall_5: 0.4140\n",
            "Epoch 62/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 0.9443 - accuracy: 0.6752 - precision_5: 0.8124 - recall_5: 0.5185 - val_loss: 1.1489 - val_accuracy: 0.5819 - val_precision_5: 0.7133 - val_recall_5: 0.4195\n",
            "Epoch 63/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 0.9372 - accuracy: 0.6769 - precision_5: 0.8161 - recall_5: 0.5238 - val_loss: 1.1479 - val_accuracy: 0.5835 - val_precision_5: 0.7139 - val_recall_5: 0.4186\n",
            "Epoch 64/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 0.9355 - accuracy: 0.6763 - precision_5: 0.8121 - recall_5: 0.5221 - val_loss: 1.1481 - val_accuracy: 0.5833 - val_precision_5: 0.7180 - val_recall_5: 0.4170\n",
            "Epoch 65/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 0.9280 - accuracy: 0.6794 - precision_5: 0.8162 - recall_5: 0.5281 - val_loss: 1.1475 - val_accuracy: 0.5830 - val_precision_5: 0.7134 - val_recall_5: 0.4204\n",
            "Epoch 66/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 0.9309 - accuracy: 0.6776 - precision_5: 0.8125 - recall_5: 0.5268 - val_loss: 1.1477 - val_accuracy: 0.5810 - val_precision_5: 0.7174 - val_recall_5: 0.4135\n",
            "Epoch 67/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 0.9250 - accuracy: 0.6804 - precision_5: 0.8156 - recall_5: 0.5286 - val_loss: 1.1468 - val_accuracy: 0.5817 - val_precision_5: 0.7125 - val_recall_5: 0.4252\n",
            "Epoch 68/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 0.9211 - accuracy: 0.6829 - precision_5: 0.8149 - recall_5: 0.5334 - val_loss: 1.1485 - val_accuracy: 0.5821 - val_precision_5: 0.7136 - val_recall_5: 0.4206\n",
            "Epoch 69/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 0.9153 - accuracy: 0.6856 - precision_5: 0.8164 - recall_5: 0.5358 - val_loss: 1.1468 - val_accuracy: 0.5828 - val_precision_5: 0.7106 - val_recall_5: 0.4225\n",
            "Epoch 70/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 0.9092 - accuracy: 0.6889 - precision_5: 0.8183 - recall_5: 0.5431 - val_loss: 1.1472 - val_accuracy: 0.5847 - val_precision_5: 0.7132 - val_recall_5: 0.4193\n",
            "Epoch 71/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 0.9085 - accuracy: 0.6877 - precision_5: 0.8209 - recall_5: 0.5413 - val_loss: 1.1483 - val_accuracy: 0.5828 - val_precision_5: 0.7117 - val_recall_5: 0.4209\n",
            "Epoch 72/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 0.9062 - accuracy: 0.6873 - precision_5: 0.8179 - recall_5: 0.5391 - val_loss: 1.1481 - val_accuracy: 0.5826 - val_precision_5: 0.7053 - val_recall_5: 0.4266\n",
            "136/136 [==============================] - 0s 3ms/step - loss: 1.1258 - accuracy: 0.6006 - precision_5: 0.7143 - recall_5: 0.4326\n",
            "Loss: 1.13, Accuracy: 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss: 1.13, Accuracy: 0.6, Precision: 0.71, Recall: 0.43."
      ],
      "metadata": {
        "id": "HpkhgRbCOi7_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Terza prova"
      ],
      "metadata": {
        "id": "ljIEAKMRRuRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lowerize(data):\n",
        "  return list(map(lambda x: x.lower(), data))\n",
        "\n",
        "def remove_special_chars(data):\n",
        "  return list(map(lambda x: x.replace('|'.join([re.escape(c) for c in list(\"#%&*/:\\^_{|}~\")]), \"\"), data))\n",
        "\n",
        "def convert_emojis(data):\n",
        "  return list(map(lambda x: emoji.demojize(x), data))\n",
        "\n",
        "def split_contractions(data):\n",
        "  return list(map(lambda x: contractions.fix(x), data))\n",
        "\n",
        "text_processor = TextPreProcessor(normalize= ['money', 'user', 'time', 'date', 'number', 'phone'],\n",
        "                                  annotate={\"elongated\", \"repeated\", 'emphasis', 'censored'},\n",
        "                                  fix_html=True, tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
        "                                  segmenter=\"twitter\", corrector=\"twitter\", unpack_contractions=False,\n",
        "                                  spell_correct_elong=True, spell_correction=True, fix_text=True,\n",
        "                                  dicts=[emoticons])\n",
        "\n",
        "def df_preprocessing(df_pre):\n",
        "  df_pre = lowerize(df_pre)\n",
        "  df_pre = convert_emojis(df_pre)\n",
        "  df_pre = split_contractions(df_pre)\n",
        "  df_pre = list(map(lambda x: ' '.join(text_processor.pre_process_doc(x)).strip(), df_pre))\n",
        "  df_pre = remove_special_chars(df_pre)\n",
        "  return df_pre"
      ],
      "metadata": {
        "id": "CkxIEi09RtAP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8aed7cf-ef9c-4366-b6fc-7aba014ea9ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading twitter - 1grams ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [entry['text'] for entry in data]\n",
        "emotions = [entry['emotion'] for entry in data]\n",
        "\n",
        "texts = df_preprocessing(texts)\n",
        "\n",
        "max_words = 20000\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(texts)\n",
        "text_sequences = tokenizer.texts_to_sequences(texts)\n",
        "text_padded = pad_sequences(text_sequences, padding='post')\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_emotions = label_encoder.fit_transform(emotions)\n",
        "categorical_emotions = tf.keras.utils.to_categorical(encoded_emotions, num_classes=len(label_encoder.classes_))\n",
        "\n",
        "text_train, text_test_temp, emotion_train, emotion_test_temp = train_test_split(\n",
        "    text_padded, categorical_emotions, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "text_test, text_val, emotion_test, emotion_val = train_test_split(\n",
        "    text_test_temp, emotion_test_temp, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "uGjZImmeT73F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_input = layers.Input(shape=text_padded.shape[1], dtype=tf.int32)\n",
        "embedding_layer = layers.Embedding(input_dim=max_words, output_dim=8, input_length=text_padded.shape[1])(text_input)\n",
        "text_flatten = layers.Flatten()(embedding_layer)\n",
        "\n",
        "dropout_layer = layers.Dropout(0.5)(text_flatten)\n",
        "output_layer = layers.Dense(len(label_encoder.classes_), activation='softmax')(dropout_layer)\n",
        "\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model = models.Model(inputs=text_input, outputs=output_layer)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy', metrics.Precision(), metrics.Recall()])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "52jtX_h7mUyZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8d83b66-711f-4561-bf47-1787ec285b56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_11 (InputLayer)       [(None, 485)]             0         \n",
            "                                                                 \n",
            " embedding_7 (Embedding)     (None, 485, 8)            160000    \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 3880)              0         \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 3880)              0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 7)                 27167     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 187167 (731.12 KB)\n",
            "Trainable params: 187167 (731.12 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(text_train, emotion_train, epochs=EPOCH, validation_data=(text_val, emotion_val), callbacks=[checkpoint_callback, early_stopping_callback])\n",
        "\n",
        "evaluation_results = model.evaluate(text_test, emotion_test)\n",
        "print(f\"Loss: {round(evaluation_results[0], 2)}, Accuracy: {round(evaluation_results[1], 2)}\")"
      ],
      "metadata": {
        "id": "08d7_l3TmYsX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "515b9045-514d-4159-927b-55d207721165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1086/1086 [==============================] - 15s 13ms/step - loss: 1.5560 - accuracy: 0.3679 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1.5235 - val_accuracy: 0.3673 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
            "Epoch 2/100\n",
            "1086/1086 [==============================] - 6s 5ms/step - loss: 1.5273 - accuracy: 0.3747 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1.5152 - val_accuracy: 0.3673 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
            "Epoch 3/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.5123 - accuracy: 0.3843 - precision_7: 1.0000 - recall_7: 5.7590e-04 - val_loss: 1.4913 - val_accuracy: 0.3955 - val_precision_7: 1.0000 - val_recall_7: 5.7571e-04\n",
            "Epoch 4/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.4846 - accuracy: 0.4252 - precision_7: 0.9317 - recall_7: 0.0251 - val_loss: 1.4608 - val_accuracy: 0.4398 - val_precision_7: 0.9577 - val_recall_7: 0.0391\n",
            "Epoch 5/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.4533 - accuracy: 0.4566 - precision_7: 0.8822 - recall_7: 0.0761 - val_loss: 1.4291 - val_accuracy: 0.4836 - val_precision_7: 0.9349 - val_recall_7: 0.0910\n",
            "Epoch 6/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 1.4230 - accuracy: 0.4802 - precision_7: 0.8417 - recall_7: 0.1135 - val_loss: 1.3989 - val_accuracy: 0.4859 - val_precision_7: 0.8907 - val_recall_7: 0.1267\n",
            "Epoch 7/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 1.3958 - accuracy: 0.4943 - precision_7: 0.8234 - recall_7: 0.1401 - val_loss: 1.3733 - val_accuracy: 0.4957 - val_precision_7: 0.8413 - val_recall_7: 0.1618\n",
            "Epoch 8/100\n",
            "1086/1086 [==============================] - 6s 5ms/step - loss: 1.3716 - accuracy: 0.5061 - precision_7: 0.8188 - recall_7: 0.1632 - val_loss: 1.3500 - val_accuracy: 0.5037 - val_precision_7: 0.8503 - val_recall_7: 0.1733\n",
            "Epoch 9/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 1.3506 - accuracy: 0.5127 - precision_7: 0.8086 - recall_7: 0.1821 - val_loss: 1.3295 - val_accuracy: 0.5291 - val_precision_7: 0.8303 - val_recall_7: 0.1860\n",
            "Epoch 10/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.3291 - accuracy: 0.5223 - precision_7: 0.8019 - recall_7: 0.2014 - val_loss: 1.3103 - val_accuracy: 0.5262 - val_precision_7: 0.8463 - val_recall_7: 0.1934\n",
            "Epoch 11/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 1.3117 - accuracy: 0.5274 - precision_7: 0.7982 - recall_7: 0.2152 - val_loss: 1.2949 - val_accuracy: 0.5320 - val_precision_7: 0.8152 - val_recall_7: 0.2159\n",
            "Epoch 12/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 1.2974 - accuracy: 0.5313 - precision_7: 0.7916 - recall_7: 0.2277 - val_loss: 1.2793 - val_accuracy: 0.5458 - val_precision_7: 0.8182 - val_recall_7: 0.2124\n",
            "Epoch 13/100\n",
            "1086/1086 [==============================] - 6s 5ms/step - loss: 1.2799 - accuracy: 0.5413 - precision_7: 0.7931 - recall_7: 0.2474 - val_loss: 1.2656 - val_accuracy: 0.5521 - val_precision_7: 0.7953 - val_recall_7: 0.2326\n",
            "Epoch 14/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.2674 - accuracy: 0.5464 - precision_7: 0.7903 - recall_7: 0.2583 - val_loss: 1.2543 - val_accuracy: 0.5533 - val_precision_7: 0.8112 - val_recall_7: 0.2424\n",
            "Epoch 15/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.2556 - accuracy: 0.5499 - precision_7: 0.7885 - recall_7: 0.2697 - val_loss: 1.2422 - val_accuracy: 0.5625 - val_precision_7: 0.8026 - val_recall_7: 0.2527\n",
            "Epoch 16/100\n",
            "1086/1086 [==============================] - 6s 5ms/step - loss: 1.2410 - accuracy: 0.5544 - precision_7: 0.7889 - recall_7: 0.2823 - val_loss: 1.2331 - val_accuracy: 0.5630 - val_precision_7: 0.8093 - val_recall_7: 0.2516\n",
            "Epoch 17/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.2299 - accuracy: 0.5600 - precision_7: 0.7877 - recall_7: 0.2946 - val_loss: 1.2244 - val_accuracy: 0.5717 - val_precision_7: 0.8221 - val_recall_7: 0.2447\n",
            "Epoch 18/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.2204 - accuracy: 0.5623 - precision_7: 0.7900 - recall_7: 0.2993 - val_loss: 1.2136 - val_accuracy: 0.5665 - val_precision_7: 0.7871 - val_recall_7: 0.2746\n",
            "Epoch 19/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.2083 - accuracy: 0.5669 - precision_7: 0.7907 - recall_7: 0.3138 - val_loss: 1.2054 - val_accuracy: 0.5711 - val_precision_7: 0.7771 - val_recall_7: 0.2850\n",
            "Epoch 20/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 1.1981 - accuracy: 0.5746 - precision_7: 0.7882 - recall_7: 0.3256 - val_loss: 1.1991 - val_accuracy: 0.5774 - val_precision_7: 0.7797 - val_recall_7: 0.2913\n",
            "Epoch 21/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.1884 - accuracy: 0.5763 - precision_7: 0.7861 - recall_7: 0.3324 - val_loss: 1.1904 - val_accuracy: 0.5792 - val_precision_7: 0.7616 - val_recall_7: 0.3109\n",
            "Epoch 22/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 1.1788 - accuracy: 0.5807 - precision_7: 0.7825 - recall_7: 0.3426 - val_loss: 1.1858 - val_accuracy: 0.5878 - val_precision_7: 0.7958 - val_recall_7: 0.2850\n",
            "Epoch 23/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.1719 - accuracy: 0.5852 - precision_7: 0.7824 - recall_7: 0.3526 - val_loss: 1.1803 - val_accuracy: 0.5861 - val_precision_7: 0.7871 - val_recall_7: 0.3022\n",
            "Epoch 24/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.1623 - accuracy: 0.5875 - precision_7: 0.7892 - recall_7: 0.3551 - val_loss: 1.1733 - val_accuracy: 0.5855 - val_precision_7: 0.7652 - val_recall_7: 0.3264\n",
            "Epoch 25/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.1538 - accuracy: 0.5910 - precision_7: 0.7871 - recall_7: 0.3671 - val_loss: 1.1686 - val_accuracy: 0.5872 - val_precision_7: 0.7776 - val_recall_7: 0.3201\n",
            "Epoch 26/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.1457 - accuracy: 0.5932 - precision_7: 0.7878 - recall_7: 0.3709 - val_loss: 1.1640 - val_accuracy: 0.5866 - val_precision_7: 0.7566 - val_recall_7: 0.3472\n",
            "Epoch 27/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 1.1358 - accuracy: 0.5995 - precision_7: 0.7885 - recall_7: 0.3803 - val_loss: 1.1583 - val_accuracy: 0.5895 - val_precision_7: 0.7619 - val_recall_7: 0.3500\n",
            "Epoch 28/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 1.1315 - accuracy: 0.6009 - precision_7: 0.7847 - recall_7: 0.3841 - val_loss: 1.1556 - val_accuracy: 0.5912 - val_precision_7: 0.7494 - val_recall_7: 0.3702\n",
            "Epoch 29/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.1262 - accuracy: 0.6040 - precision_7: 0.7879 - recall_7: 0.3925 - val_loss: 1.1516 - val_accuracy: 0.5953 - val_precision_7: 0.7683 - val_recall_7: 0.3437\n",
            "Epoch 30/100\n",
            "  39/1086 [>.............................] - ETA: 4s - loss: 1.1078 - accuracy: 0.6194 - precision_7: 0.8032 - recall_7: 0.3990"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1086/1086 [==============================] - 5s 4ms/step - loss: 1.1161 - accuracy: 0.6073 - precision_7: 0.7914 - recall_7: 0.3977 - val_loss: 1.1470 - val_accuracy: 0.5936 - val_precision_7: 0.7628 - val_recall_7: 0.3610\n",
            "Epoch 31/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.1109 - accuracy: 0.6068 - precision_7: 0.7849 - recall_7: 0.3989 - val_loss: 1.1448 - val_accuracy: 0.5924 - val_precision_7: 0.7438 - val_recall_7: 0.3794\n",
            "Epoch 32/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.1015 - accuracy: 0.6124 - precision_7: 0.7912 - recall_7: 0.4079 - val_loss: 1.1424 - val_accuracy: 0.5953 - val_precision_7: 0.7557 - val_recall_7: 0.3794\n",
            "Epoch 33/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.1014 - accuracy: 0.6115 - precision_7: 0.7866 - recall_7: 0.4084 - val_loss: 1.1391 - val_accuracy: 0.5918 - val_precision_7: 0.7461 - val_recall_7: 0.3857\n",
            "Epoch 34/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.0929 - accuracy: 0.6139 - precision_7: 0.7865 - recall_7: 0.4188 - val_loss: 1.1364 - val_accuracy: 0.5959 - val_precision_7: 0.7599 - val_recall_7: 0.3661\n",
            "Epoch 35/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 1.0821 - accuracy: 0.6206 - precision_7: 0.7884 - recall_7: 0.4233 - val_loss: 1.1347 - val_accuracy: 0.5999 - val_precision_7: 0.7629 - val_recall_7: 0.3667\n",
            "Epoch 36/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 1.0774 - accuracy: 0.6207 - precision_7: 0.7912 - recall_7: 0.4288 - val_loss: 1.1323 - val_accuracy: 0.5936 - val_precision_7: 0.7547 - val_recall_7: 0.3685\n",
            "Epoch 37/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.0754 - accuracy: 0.6216 - precision_7: 0.7899 - recall_7: 0.4290 - val_loss: 1.1305 - val_accuracy: 0.5947 - val_precision_7: 0.7557 - val_recall_7: 0.3811\n",
            "Epoch 38/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.0667 - accuracy: 0.6262 - precision_7: 0.7937 - recall_7: 0.4373 - val_loss: 1.1275 - val_accuracy: 0.5964 - val_precision_7: 0.7561 - val_recall_7: 0.3731\n",
            "Epoch 39/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.0595 - accuracy: 0.6292 - precision_7: 0.7956 - recall_7: 0.4407 - val_loss: 1.1270 - val_accuracy: 0.5982 - val_precision_7: 0.7526 - val_recall_7: 0.3782\n",
            "Epoch 40/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.0550 - accuracy: 0.6303 - precision_7: 0.7971 - recall_7: 0.4462 - val_loss: 1.1249 - val_accuracy: 0.5999 - val_precision_7: 0.7444 - val_recall_7: 0.3840\n",
            "Epoch 41/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.0513 - accuracy: 0.6305 - precision_7: 0.7958 - recall_7: 0.4474 - val_loss: 1.1232 - val_accuracy: 0.5993 - val_precision_7: 0.7398 - val_recall_7: 0.3880\n",
            "Epoch 42/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 1.0426 - accuracy: 0.6344 - precision_7: 0.7957 - recall_7: 0.4544 - val_loss: 1.1203 - val_accuracy: 0.5964 - val_precision_7: 0.7420 - val_recall_7: 0.4007\n",
            "Epoch 43/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.0388 - accuracy: 0.6383 - precision_7: 0.7946 - recall_7: 0.4553 - val_loss: 1.1203 - val_accuracy: 0.5999 - val_precision_7: 0.7454 - val_recall_7: 0.3944\n",
            "Epoch 44/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 1.0328 - accuracy: 0.6389 - precision_7: 0.7951 - recall_7: 0.4605 - val_loss: 1.1177 - val_accuracy: 0.6005 - val_precision_7: 0.7362 - val_recall_7: 0.4064\n",
            "Epoch 45/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 1.0298 - accuracy: 0.6413 - precision_7: 0.7970 - recall_7: 0.4635 - val_loss: 1.1174 - val_accuracy: 0.5953 - val_precision_7: 0.7386 - val_recall_7: 0.4099\n",
            "Epoch 46/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 1.0224 - accuracy: 0.6420 - precision_7: 0.8003 - recall_7: 0.4664 - val_loss: 1.1156 - val_accuracy: 0.5953 - val_precision_7: 0.7402 - val_recall_7: 0.4036\n",
            "Epoch 47/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 1.0191 - accuracy: 0.6427 - precision_7: 0.7939 - recall_7: 0.4681 - val_loss: 1.1157 - val_accuracy: 0.5953 - val_precision_7: 0.7396 - val_recall_7: 0.4088\n",
            "Epoch 48/100\n",
            "1086/1086 [==============================] - 6s 5ms/step - loss: 1.0156 - accuracy: 0.6466 - precision_7: 0.7976 - recall_7: 0.4737 - val_loss: 1.1138 - val_accuracy: 0.5953 - val_precision_7: 0.7439 - val_recall_7: 0.4047\n",
            "Epoch 49/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 1.0123 - accuracy: 0.6460 - precision_7: 0.7998 - recall_7: 0.4772 - val_loss: 1.1138 - val_accuracy: 0.5964 - val_precision_7: 0.7375 - val_recall_7: 0.4157\n",
            "Epoch 50/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 1.0047 - accuracy: 0.6492 - precision_7: 0.7979 - recall_7: 0.4787 - val_loss: 1.1128 - val_accuracy: 0.5947 - val_precision_7: 0.7423 - val_recall_7: 0.4162\n",
            "Epoch 51/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 0.9981 - accuracy: 0.6530 - precision_7: 0.7989 - recall_7: 0.4862 - val_loss: 1.1130 - val_accuracy: 0.5964 - val_precision_7: 0.7462 - val_recall_7: 0.3909\n",
            "Epoch 52/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 0.9951 - accuracy: 0.6525 - precision_7: 0.7999 - recall_7: 0.4866 - val_loss: 1.1119 - val_accuracy: 0.5953 - val_precision_7: 0.7275 - val_recall_7: 0.4243\n",
            "Epoch 53/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 0.9858 - accuracy: 0.6558 - precision_7: 0.8018 - recall_7: 0.4928 - val_loss: 1.1113 - val_accuracy: 0.5970 - val_precision_7: 0.7384 - val_recall_7: 0.4111\n",
            "Epoch 54/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 0.9823 - accuracy: 0.6581 - precision_7: 0.8037 - recall_7: 0.4944 - val_loss: 1.1104 - val_accuracy: 0.5993 - val_precision_7: 0.7343 - val_recall_7: 0.4105\n",
            "Epoch 55/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 0.9811 - accuracy: 0.6577 - precision_7: 0.8008 - recall_7: 0.4939 - val_loss: 1.1116 - val_accuracy: 0.5982 - val_precision_7: 0.7278 - val_recall_7: 0.4203\n",
            "Epoch 56/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 0.9742 - accuracy: 0.6608 - precision_7: 0.8051 - recall_7: 0.5010 - val_loss: 1.1101 - val_accuracy: 0.5987 - val_precision_7: 0.7328 - val_recall_7: 0.4168\n",
            "Epoch 57/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 0.9679 - accuracy: 0.6628 - precision_7: 0.8037 - recall_7: 0.5011 - val_loss: 1.1103 - val_accuracy: 0.5964 - val_precision_7: 0.7283 - val_recall_7: 0.4197\n",
            "Epoch 58/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 0.9666 - accuracy: 0.6650 - precision_7: 0.8042 - recall_7: 0.5042 - val_loss: 1.1101 - val_accuracy: 0.5964 - val_precision_7: 0.7315 - val_recall_7: 0.4220\n",
            "Epoch 59/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 0.9602 - accuracy: 0.6680 - precision_7: 0.8079 - recall_7: 0.5109 - val_loss: 1.1119 - val_accuracy: 0.5936 - val_precision_7: 0.7248 - val_recall_7: 0.4185\n",
            "Epoch 60/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 0.9587 - accuracy: 0.6679 - precision_7: 0.8066 - recall_7: 0.5096 - val_loss: 1.1099 - val_accuracy: 0.5959 - val_precision_7: 0.7255 - val_recall_7: 0.4185\n",
            "Epoch 61/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 0.9552 - accuracy: 0.6660 - precision_7: 0.8036 - recall_7: 0.5126 - val_loss: 1.1113 - val_accuracy: 0.5953 - val_precision_7: 0.7259 - val_recall_7: 0.4116\n",
            "Epoch 62/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 0.9506 - accuracy: 0.6701 - precision_7: 0.8064 - recall_7: 0.5156 - val_loss: 1.1106 - val_accuracy: 0.5930 - val_precision_7: 0.7162 - val_recall_7: 0.4272\n",
            "Epoch 63/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 0.9428 - accuracy: 0.6747 - precision_7: 0.8080 - recall_7: 0.5223 - val_loss: 1.1116 - val_accuracy: 0.5970 - val_precision_7: 0.7263 - val_recall_7: 0.4139\n",
            "Epoch 64/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 0.9368 - accuracy: 0.6731 - precision_7: 0.8082 - recall_7: 0.5219 - val_loss: 1.1093 - val_accuracy: 0.5964 - val_precision_7: 0.7211 - val_recall_7: 0.4272\n",
            "Epoch 65/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 0.9375 - accuracy: 0.6725 - precision_7: 0.8098 - recall_7: 0.5235 - val_loss: 1.1121 - val_accuracy: 0.5912 - val_precision_7: 0.7093 - val_recall_7: 0.4370\n",
            "Epoch 66/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 0.9364 - accuracy: 0.6773 - precision_7: 0.8062 - recall_7: 0.5276 - val_loss: 1.1100 - val_accuracy: 0.5930 - val_precision_7: 0.7167 - val_recall_7: 0.4312\n",
            "Epoch 67/100\n",
            "1086/1086 [==============================] - 5s 5ms/step - loss: 0.9285 - accuracy: 0.6795 - precision_7: 0.8086 - recall_7: 0.5303 - val_loss: 1.1111 - val_accuracy: 0.5930 - val_precision_7: 0.7137 - val_recall_7: 0.4306\n",
            "Epoch 68/100\n",
            "1086/1086 [==============================] - 5s 4ms/step - loss: 0.9285 - accuracy: 0.6801 - precision_7: 0.8065 - recall_7: 0.5343 - val_loss: 1.1131 - val_accuracy: 0.5930 - val_precision_7: 0.7197 - val_recall_7: 0.4301\n",
            "Epoch 69/100\n",
            "1086/1086 [==============================] - 4s 4ms/step - loss: 0.9215 - accuracy: 0.6800 - precision_7: 0.8124 - recall_7: 0.5348 - val_loss: 1.1140 - val_accuracy: 0.5959 - val_precision_7: 0.7212 - val_recall_7: 0.4185\n",
            "218/218 [==============================] - 1s 4ms/step - loss: 1.1164 - accuracy: 0.5955 - precision_7: 0.7229 - recall_7: 0.4350\n",
            "Loss: 1.12, Accuracy: 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss: 1.12, Accuracy: 0.6, Precision: 0.72, Recall: 0.4."
      ],
      "metadata": {
        "id": "ajntLyWg4SG_"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}