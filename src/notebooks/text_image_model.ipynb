{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVlvNevZo1Oh",
        "outputId": "1cd733d2-9751-4c74-b169-87aed484e365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/AIExam/data.zip /content\n",
        "!unzip data.zip"
      ],
      "metadata": {
        "id": "acBq0WM-QyzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import LSTM, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import csv\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Function to load data from CSV and images\n",
        "def load_data(file_path):\n",
        "    data = []\n",
        "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
        "        csv_reader = csv.reader(csvfile)\n",
        "        next(csv_reader, None)\n",
        "        for row in csv_reader:\n",
        "            text, image_path, emotion = row\n",
        "            img = Image.open(image_path).convert('RGB')\n",
        "            img = img.resize((64, 64))\n",
        "            img_array = np.array(img) / 255.0\n",
        "            entry = {'text': text, 'image_data': img_array, 'emotion': emotion}\n",
        "            data.append(entry)\n",
        "    return data\n",
        "\n",
        "\n",
        "file_path = \"data/processed/text_image_emotion.csv\"\n",
        "data = load_data(file_path)"
      ],
      "metadata": {
        "id": "1YJojNd8uctg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to numpy arrays\n",
        "texts = [entry['text'] for entry in data]\n",
        "images = np.array([entry['image_data'] for entry in data])\n",
        "emotions = [entry['emotion'] for entry in data]\n",
        "\n",
        "# Encode emotions\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_emotions = label_encoder.fit_transform(emotions)\n",
        "categorical_emotions = tf.keras.utils.to_categorical(encoded_emotions, num_classes=len(label_encoder.classes_))\n",
        "\n",
        "# Tokenize the text\n",
        "max_words = 10000\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(texts)\n",
        "text_sequences = tokenizer.texts_to_sequences(texts)\n",
        "text_padded = pad_sequences(text_sequences, padding='post')\n",
        "\n",
        "# Split data into training, testing and validation sets\n",
        "text_train, text_test_temp, image_train, image_test_temp, emotion_train, emotion_test_temp = train_test_split(\n",
        "    text_padded, images, categorical_emotions, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "text_test, text_val, image_test, image_val, emotion_test, emotion_val = train_test_split(\n",
        "    text_test_temp, image_test_temp, emotion_test_temp, test_size=0.5, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "nWZ8cAV8uqRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the neural network model\n",
        "text_input = layers.Input(shape=(text_padded.shape[1],), dtype=tf.int32)\n",
        "embedding_layer = layers.Embedding(input_dim=max_words, output_dim=16, input_length=text_padded.shape[1])(text_input)\n",
        "lstm_layer = LSTM(16)(embedding_layer)\n",
        "text_flatten = layers.Flatten()(lstm_layer)\n",
        "\n",
        "image_input = layers.Input(shape=(64, 64, 3))\n",
        "conv_layer = layers.Conv2D(32, (3, 3), activation='relu')(image_input)\n",
        "pooling_layer = layers.MaxPooling2D((2, 2))(conv_layer)\n",
        "flatten_layer = layers.Flatten()(pooling_layer)\n",
        "\n",
        "# Concatenate the flattened text and image layers\n",
        "concatenated = layers.Concatenate()([text_flatten, flatten_layer])\n",
        "# Add Dropout for regularization\n",
        "dropout_layer = layers.Dropout(0.5)(concatenated)\n",
        "dense_layer = layers.Dense(64, activation='relu')(dropout_layer)\n",
        "output_layer = layers.Dense(len(label_encoder.classes_), activation='softmax')(dense_layer)\n",
        "\n",
        "model = models.Model(inputs=[text_input, image_input], outputs=output_layer)\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Add ModelCheckpoint callback to save the best model\n",
        "checkpoint_callback = ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor=\"val_accuracy\", mode=\"max\")\n",
        "\n",
        "# Create an ImageDataGenerator for data augmentation\n",
        "image_data_generator = ImageDataGenerator(rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "\n",
        "# callback per l'early stopping\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT1dMa5Uuxzu",
        "outputId": "7aee2199-db7c-42b7-fa1a-c9a9c9324023"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 34)]                 0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 64, 64, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, 34, 16)               160000    ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 62, 62, 32)           896       ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 (None, 16)                   2112      ['embedding[0][0]']           \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 31, 31, 32)           0         ['conv2d[0][0]']              \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 16)                   0         ['lstm[0][0]']                \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)         (None, 30752)                0         ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 30768)                0         ['flatten[0][0]',             \n",
            "                                                                     'flatten_1[0][0]']           \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 30768)                0         ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 64)                   1969216   ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 7)                    455       ['dense[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2132679 (8.14 MB)\n",
            "Trainable params: 2132679 (8.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "KAhvriwdqhHS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77da9c8d-1edc-4a02-be61-87eaffbed31a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "584/585 [============================>.] - ETA: 0s - loss: 1.6822 - accuracy: 0.3221"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r585/585 [==============================] - 29s 39ms/step - loss: 1.6819 - accuracy: 0.3222 - val_loss: 1.6019 - val_accuracy: 0.3949\n",
            "Epoch 2/30\n",
            "585/585 [==============================] - 5s 9ms/step - loss: 1.5754 - accuracy: 0.3974 - val_loss: 1.5214 - val_accuracy: 0.4265\n",
            "Epoch 3/30\n",
            "585/585 [==============================] - 6s 9ms/step - loss: 1.5095 - accuracy: 0.4376 - val_loss: 1.4809 - val_accuracy: 0.4355\n",
            "Epoch 4/30\n",
            "585/585 [==============================] - 5s 9ms/step - loss: 1.4090 - accuracy: 0.4846 - val_loss: 1.3561 - val_accuracy: 0.5013\n",
            "Epoch 5/30\n",
            "585/585 [==============================] - 7s 12ms/step - loss: 1.2936 - accuracy: 0.5318 - val_loss: 1.3366 - val_accuracy: 0.4923\n",
            "Epoch 6/30\n",
            "585/585 [==============================] - 4s 7ms/step - loss: 1.2203 - accuracy: 0.5615 - val_loss: 1.2681 - val_accuracy: 0.5359\n",
            "Epoch 7/30\n",
            "585/585 [==============================] - 5s 9ms/step - loss: 1.1640 - accuracy: 0.5806 - val_loss: 1.2541 - val_accuracy: 0.5355\n",
            "Epoch 8/30\n",
            "585/585 [==============================] - 5s 9ms/step - loss: 1.1179 - accuracy: 0.6027 - val_loss: 1.2617 - val_accuracy: 0.5184\n",
            "Epoch 9/30\n",
            "585/585 [==============================] - 5s 8ms/step - loss: 1.0771 - accuracy: 0.6164 - val_loss: 1.2418 - val_accuracy: 0.5444\n",
            "Epoch 10/30\n",
            "585/585 [==============================] - 5s 9ms/step - loss: 1.0367 - accuracy: 0.6325 - val_loss: 1.2364 - val_accuracy: 0.5496\n",
            "Epoch 11/30\n",
            "585/585 [==============================] - 4s 7ms/step - loss: 1.0006 - accuracy: 0.6476 - val_loss: 1.2336 - val_accuracy: 0.5551\n",
            "Epoch 12/30\n",
            "585/585 [==============================] - 4s 7ms/step - loss: 0.9701 - accuracy: 0.6606 - val_loss: 1.2567 - val_accuracy: 0.5491\n",
            "Epoch 13/30\n",
            "585/585 [==============================] - 6s 11ms/step - loss: 0.9381 - accuracy: 0.6714 - val_loss: 1.2470 - val_accuracy: 0.5585\n",
            "Epoch 14/30\n",
            "585/585 [==============================] - 5s 9ms/step - loss: 0.9070 - accuracy: 0.6821 - val_loss: 1.2433 - val_accuracy: 0.5709\n",
            "Epoch 15/30\n",
            "585/585 [==============================] - 4s 7ms/step - loss: 0.8804 - accuracy: 0.6948 - val_loss: 1.2742 - val_accuracy: 0.5632\n",
            "Epoch 16/30\n",
            "585/585 [==============================] - 5s 9ms/step - loss: 0.8584 - accuracy: 0.6973 - val_loss: 1.2778 - val_accuracy: 0.5650\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c4ecf0e96f0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "\n",
        "model.fit([text_train, image_train], emotion_train, epochs=30, validation_data=([text_val, image_val], emotion_val), callbacks=[checkpoint_callback, early_stopping_callback])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results = model.evaluate([text_test, image_test], emotion_test)\n",
        "print(f\"Loss: {evaluation_results[0]}, Accuracy: {evaluation_results[1]}\")\n",
        "\n",
        "# TODO: cambiare dati\n",
        "#predictions = model.predict([text_test, image_test])\n",
        "#print(predictions)"
      ],
      "metadata": {
        "id": "axTQtzfZvWAX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a552a6f-e272-49ba-c55c-35c58d0374c8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74/74 [==============================] - 0s 4ms/step - loss: 1.2396 - accuracy: 0.5675\n",
            "Loss: 1.2395706176757812, Accuracy: 0.5675213932991028\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "XO1g-sXM67RE",
        "ZMJMJv39q2_A",
        "wGaIsKTZwAyk",
        "pLVj68WNbroz",
        "_A_fUtfewLbt",
        "027rYoBZAOjM",
        "OH5MFA5QQHre",
        "72I3_3flS4VN",
        "tCmBnkKhPNZq",
        "DfUuXg-xQHKv",
        "aNLqQ5k_Sfih",
        "SibMuTSPUouw"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}